"""
AWS Optimization Workflow (Prompt 27)

Automated AWS cost optimization and performance monitoring.
Runs daily analysis and applies optimizations based on configuration.
"""

name: AWS Optimization

on:
  # Daily optimization analysis
  schedule:
    - cron: '0 6 * * *'  # 6 AM UTC daily

  # Weekly deep optimization
  schedule:
    - cron: '0 2 * * 0'  # 2 AM UTC on Sundays

  # Manual trigger
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'Type of analysis to run'
        required: true
        default: 'analyze'
        type: choice
        options:
          - analyze
          - optimize
          - report

      apply_optimizations:
        description: 'Apply optimizations (use with caution)'
        required: false
        default: false
        type: boolean

      email_report:
        description: 'Email address for report (optional)'
        required: false
        type: string

jobs:
  aws-optimization-analysis:
    name: AWS Optimization Analysis
    runs-on: ubuntu-latest
    if: >
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.analysis_type == 'analyze')

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install boto3 pyyaml

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Run AWS optimization analysis
      id: analysis
      run: |
        python scripts/run_aws_optimization.py analyze \
          --output aws_optimization_report.json \
          --verbose

    - name: Parse optimization report
      if: always()
      run: |
        if [ -f "aws_optimization_report.json" ]; then
          echo "## ðŸ’° AWS Optimization Report" >> $GITHUB_STEP_SUMMARY

          # Extract key metrics using Python
          python -c "
import json
import sys

try:
    with open('aws_optimization_report.json', 'r') as f:
        report = json.load(f)

    print(f'| Metric | Value |', file=sys.stderr)
    print(f'|--------|-------|', file=sys.stderr)
    print(f'| Projected Savings | \${report.get(\"total_projected_savings\", 0):.2f}/month |', file=sys.stderr)
    print(f'| Analysis Time | {report.get(\"timestamp\", \"N/A\")} |', file=sys.stderr)
    print(f'', file=sys.stderr)

    # S3 Analysis Summary
    s3_analysis = report.get('s3_analysis', {})
    if s3_analysis:
        total_size = sum(bucket.get('total_size_gb', 0) for bucket in s3_analysis.values())
        total_cost = sum(bucket.get('cost_estimate_monthly', 0) for bucket in s3_analysis.values())
        print(f'### ðŸ—ƒï¸ S3 Storage Analysis', file=sys.stderr)
        print(f'- **Total Size**: {total_size:.2f} GB', file=sys.stderr)
        print(f'- **Monthly Cost**: \${total_cost:.2f}', file=sys.stderr)
        print(f'- **Buckets Analyzed**: {len(s3_analysis)}', file=sys.stderr)
        print(f'', file=sys.stderr)

    # Priority Recommendations
    recommendations = report.get('priority_recommendations', [])
    if recommendations:
        print(f'### ðŸŽ¯ Priority Recommendations', file=sys.stderr)
        for rec in recommendations[:3]:  # Top 3
            print(f'- {rec}', file=sys.stderr)
        print(f'', file=sys.stderr)

    # Rate Limiting Stats
    rate_stats = report.get('rate_limit_stats', {})
    if rate_stats:
        print(f'### ðŸ“Š API Usage', file=sys.stderr)
        for service, stats in rate_stats.items():
            util = stats.get('utilization_percent', 0)
            cost = stats.get('total_cost', 0)
            print(f'- **{service.upper()}**: {util:.1f}% utilization, \${cost:.3f} cost', file=sys.stderr)

except Exception as e:
    print(f'Error parsing report: {e}', file=sys.stderr)
" 2>> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ AWS optimization report not generated" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload analysis results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: aws-optimization-analysis
        path: |
          aws_optimization_report.json
          aws_optimization.log

    - name: Check for high costs
      if: always()
      run: |
        if [ -f "aws_optimization_report.json" ]; then
          # Check if projected savings exceed threshold
          SAVINGS=$(python -c "
import json
try:
    with open('aws_optimization_report.json', 'r') as f:
        report = json.load(f)
    print(report.get('total_projected_savings', 0))
except:
    print('0')
")

          if (( $(echo "$SAVINGS > 100" | bc -l) )); then
            echo "HIGH_COST_OPPORTUNITY=true" >> $GITHUB_ENV
            echo "PROJECTED_SAVINGS=$SAVINGS" >> $GITHUB_ENV
          fi
        fi

    - name: Notify about high cost opportunities
      if: env.HIGH_COST_OPPORTUNITY == 'true'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: |
        if [ ! -z "$SLACK_WEBHOOK_URL" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ðŸ’° AWS Optimization Alert: \$${PROJECTED_SAVINGS}/month potential savings identified. Check GitHub Actions for details.\"}" \
            "$SLACK_WEBHOOK_URL" || true
        fi

  aws-optimization-apply:
    name: Apply AWS Optimizations
    runs-on: ubuntu-latest
    if: >
      github.event_name == 'workflow_dispatch' &&
      github.event.inputs.analysis_type == 'optimize' &&
      github.event.inputs.apply_optimizations == 'true'
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install boto3 pyyaml

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Apply S3 optimizations
      id: s3_optimization
      run: |
        echo "Applying S3 optimizations..."
        python scripts/run_aws_optimization.py optimize \
          --service s3 \
          --apply \
          --verbose

    - name: Generate optimization summary
      if: always()
      run: |
        echo "## ðŸ”§ Applied Optimizations" >> $GITHUB_STEP_SUMMARY
        echo "- **S3 Lifecycle Policies**: Applied to configured buckets" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "- **Applied by**: GitHub Actions" >> $GITHUB_STEP_SUMMARY

    - name: Notify optimization completion
      if: success()
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: |
        if [ ! -z "$SLACK_WEBHOOK_URL" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"âœ… AWS optimizations applied successfully via GitHub Actions"}' \
            "$SLACK_WEBHOOK_URL" || true
        fi

  aws-status-report:
    name: AWS Status Report
    runs-on: ubuntu-latest
    if: >
      github.event_name == 'workflow_dispatch' &&
      github.event.inputs.analysis_type == 'report'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install boto3 pyyaml

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Generate status report
      run: |
        python scripts/run_aws_optimization.py report \
          --verbose

    - name: Email report (if requested)
      if: github.event.inputs.email_report != ''
      run: |
        echo "Email report functionality would send to: ${{ github.event.inputs.email_report }}"
        # Email functionality would be implemented here

  monthly-cost-analysis:
    name: Monthly Cost Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' && github.event.schedule == '0 2 * * 0'  # Weekly deep scan

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install boto3 pyyaml matplotlib  # For chart generation

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Run comprehensive analysis
      run: |
        python scripts/run_aws_optimization.py analyze \
          --output monthly_analysis.json \
          --verbose

    - name: Generate monthly report
      run: |
        python scripts/run_aws_optimization.py report \
          --email admin@maurinventures.com \
          --verbose

    - name: Upload monthly analysis
      uses: actions/upload-artifact@v3
      with:
        name: monthly-cost-analysis
        path: |
          monthly_analysis.json
          aws_optimization.log

    - name: Archive monthly data
      run: |
        # Create archive directory with timestamp
        ARCHIVE_DIR="aws-optimization-archives/$(date +%Y-%m)"
        mkdir -p "$ARCHIVE_DIR"

        # Copy analysis results
        cp monthly_analysis.json "$ARCHIVE_DIR/"
        cp aws_optimization.log "$ARCHIVE_DIR/"

        # Commit to repository for historical tracking
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add "$ARCHIVE_DIR/"
        git commit -m "Archive monthly AWS optimization analysis - $(date +%Y-%m)" || true
        git push || true